{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72f1c59a",
   "metadata": {},
   "source": [
    "# üéØ Fall Detection - YOLOv8 Training on Google Colab\n",
    "\n",
    "## üìä Dataset Overview\n",
    "- **Total images**: ~34,000\n",
    "  - Train: 28,153 images\n",
    "  - Valid: 3,505 images\n",
    "  - Test: 2,341 images\n",
    "- **Classes**: 2 (Fall, No-Fall)\n",
    "- **Distribution**: ~31% Fall, ~69% No-Fall (moderate imbalance ‚Üí s·ª≠ d·ª•ng class weights)\n",
    "\n",
    "## ‚öôÔ∏è Training Configuration\n",
    "- **Model**: YOLOv8 Nano (yolov8n.pt)\n",
    "- **Image size**: 640x640\n",
    "- **Epochs**: 50 (with early stopping)\n",
    "- **Batch size**: Auto (t·ª± ƒë·ªông ƒëi·ªÅu ch·ªânh theo GPU)\n",
    "- **Precision**: FP16 AMP (Mixed Precision - tƒÉng t·ªëc 2x)\n",
    "- **Augmentation**: T·ªëi ∆∞u cho fall detection (motion blur, reduced geometric transforms)\n",
    "- **Class weights**: Auto-calculated (x·ª≠ l√Ω imbalance 31:69)\n",
    "\n",
    "## üöÄ Quick Start\n",
    "1. Mount Google Drive (l∆∞u model t·ª± ƒë·ªông)\n",
    "2. Upload dataset zip l√™n Drive ho·∫∑c Colab\n",
    "3. Gi·∫£i n√©n dataset\n",
    "4. Run all cells\n",
    "5. Model t·ª± ƒë·ªông l∆∞u v√†o Drive: `/content/drive/MyDrive/fall_detection_models/best.pt`\n",
    "\n",
    "## üìà Expected Results\n",
    "- **mAP50**: 88-95% (improved from 85-92%)\n",
    "- **mAP50-95**: 75-85% (improved from 70-80%)\n",
    "- **Recall (Fall class)**: 85-90%\n",
    "- **Training time**: 1.5-2.5 hours (GPU T4 with FP16)\n",
    "\n",
    "## üîß Optimizations Applied\n",
    "- ‚úÖ FP16 Mixed Precision (amp=True)\n",
    "- ‚úÖ Auto batch sizing (batch=-1)\n",
    "- ‚úÖ Class weights for imbalance\n",
    "- ‚úÖ Warmup epochs for stability\n",
    "- ‚úÖ Reduced aggressive augmentation\n",
    "- ‚úÖ Motion blur for realistic fall scenarios\n",
    "- ‚úÖ Google Drive auto-save\n",
    "- ‚úÖ Minimal checkpointing (only best model)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee90f849",
   "metadata": {},
   "source": [
    "## Cell 1: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f188a1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install ultralytics (YOLOv8)\n",
    "!pip install -q ultralytics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7233db53",
   "metadata": {},
   "source": [
    "## Cell 2: Import Libraries & Check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2eb99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "# Check GPU\n",
    "print(f\"Torch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ecf6e8",
   "metadata": {},
   "source": [
    "## Cell 3: Upload Dataset to Kaggle\n",
    "**IMPORTANT:** Tr∆∞·ªõc khi ch·∫°y notebook n√†y:\n",
    "1. Zip to√†n b·ªô folder `data/` t·ª´ local (bao g·ªìm train/valid/test v√† data.yaml)\n",
    "2. Upload file zip l√™n Kaggle Dataset (t·∫°o dataset m·ªõi)\n",
    "3. Add dataset v√†o notebook qua \"Add data\" button\n",
    "4. Dataset s·∫Ω mount t·∫°i `/kaggle/input/your-dataset-name/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1aada73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "print(\"‚úì Google Drive mounted\")\n",
    "print(\"\\nDrive path: /content/drive/MyDrive/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601549c6",
   "metadata": {},
   "source": [
    "## Cell 4: Check Dataset Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3dbcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thay 'fall-detection-dataset' b·∫±ng t√™n dataset c·ªßa b·∫°n\n",
    "DATASET_NAME = 'fall-detection-dataset'  # ‚Üê THAY T√äN N√ÄY\n",
    "\n",
    "# Check dataset path\n",
    "dataset_path = Path(f'/kaggle/input/{DATASET_NAME}')\n",
    "print(f\"Dataset path: {dataset_path}\")\n",
    "print(f\"Exists: {dataset_path.exists()}\")\n",
    "\n",
    "if dataset_path.exists():\n",
    "    print(\"\\nDataset structure:\")\n",
    "    !ls -lh /kaggle/input/{DATASET_NAME}\n",
    "    \n",
    "    # Count images\n",
    "    train_imgs = list(dataset_path.glob('train/images/*'))\n",
    "    valid_imgs = list(dataset_path.glob('valid/images/*'))\n",
    "    test_imgs = list(dataset_path.glob('test/images/*'))\n",
    "    \n",
    "    print(f\"\\nTrain images: {len(train_imgs)}\")\n",
    "    print(f\"Valid images: {len(valid_imgs)}\")\n",
    "    print(f\"Test images: {len(test_imgs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf03abf",
   "metadata": {},
   "source": [
    "## Cell 5: Create/Update data.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54bc6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy dataset to working directory (Kaggle notebooks c√≥ quy·ªÅn ghi v√†o /kaggle/working)\n",
    "work_dir = Path('/kaggle/working')\n",
    "data_dir = work_dir / 'data'\n",
    "\n",
    "# T·∫°o symbolic links thay v√¨ copy (ti·∫øt ki·ªám disk space)\n",
    "import yaml\n",
    "\n",
    "# Create data.yaml\n",
    "data_yaml = {\n",
    "    'path': f'/kaggle/input/{fall_detection_dataset}',\n",
    "    'train': 'train/images',\n",
    "    'val': 'valid/images',\n",
    "    'test': 'test/images',\n",
    "    'nc': 2,\n",
    "    'names': {\n",
    "        0: 'Fall',\n",
    "        1: 'No-Fall'\n",
    "    }\n",
    "}\n",
    "\n",
    "yaml_path = work_dir / 'data.yaml'\n",
    "with open(yaml_path, 'w') as f:\n",
    "    yaml.dump(data_yaml, f, default_flow_style=False)\n",
    "\n",
    "print(\"‚úì Created data.yaml\")\n",
    "print(\"\\nContent:\")\n",
    "!cat /kaggle/working/data.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7eb6ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "def count_class_distribution(label_dir):\n",
    "    \"\"\"Count class instances from YOLO label files\"\"\"\n",
    "    class_counts = Counter()\n",
    "    \n",
    "    for label_file in Path(label_dir).glob('*.txt'):\n",
    "        with open(label_file, 'r') as f:\n",
    "            for line in f:\n",
    "                if line.strip():\n",
    "                    class_id = int(line.split()[0])\n",
    "                    class_counts[class_id] += 1\n",
    "    \n",
    "    return class_counts\n",
    "\n",
    "# Analyze train set\n",
    "train_labels = DATASET_PATH / 'train/labels'\n",
    "if train_labels.exists():\n",
    "    class_counts = count_class_distribution(train_labels)\n",
    "    total = sum(class_counts.values())\n",
    "    \n",
    "    print(\"üìä CLASS DISTRIBUTION (Training Set)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    class_names = ['Fall', 'No-Fall']\n",
    "    for class_id in sorted(class_counts.keys()):\n",
    "        count = class_counts[class_id]\n",
    "        percentage = (count / total) * 100\n",
    "        name = class_names[class_id]\n",
    "        print(f\"  {name} (class {class_id}): {count:,} instances ({percentage:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\n  Total: {total:,} instances\")\n",
    "    \n",
    "    # Calculate class weights (inverse frequency)\n",
    "    if len(class_counts) == 2:\n",
    "        class0, class1 = class_counts[0], class_counts[1]\n",
    "        ratio = max(class0, class1) / min(class0, class1)\n",
    "        \n",
    "        # Inverse frequency weights\n",
    "        weight0 = total / (2 * class0)\n",
    "        weight1 = total / (2 * class1)\n",
    "        \n",
    "        print(f\"\\n  Imbalance ratio: {ratio:.2f}:1\")\n",
    "        print(f\"\\nüéØ RECOMMENDED CLASS WEIGHTS:\")\n",
    "        print(f\"  Fall (class 0): {weight0:.3f}\")\n",
    "        print(f\"  No-Fall (class 1): {weight1:.3f}\")\n",
    "        \n",
    "        # Save for training\n",
    "        CLASS_WEIGHTS = [weight0, weight1]\n",
    "        \n",
    "        if ratio > 3:\n",
    "            print(\"\\n  ‚ö†Ô∏è  Severe imbalance! Class weights CRITICAL\")\n",
    "        elif ratio > 1.5:\n",
    "            print(\"\\n  ‚ö†Ô∏è  Moderate imbalance - class weights recommended\")\n",
    "        else:\n",
    "            print(\"\\n  ‚úì Well balanced dataset\")\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Train labels directory not found\")\n",
    "    CLASS_WEIGHTS = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff952f31",
   "metadata": {},
   "source": [
    "## Cell 5.5: Calculate Class Distribution & Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc539bf8",
   "metadata": {},
   "source": [
    "## Cell 6: Visualize Sample Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d367d41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "def show_sample_images(dataset_path, split='train', num_samples=4):\n",
    "    img_dir = dataset_path / split / 'images'\n",
    "    label_dir = dataset_path / split / 'labels'\n",
    "    \n",
    "    images = list(img_dir.glob('*'))[:num_samples]\n",
    "    \n",
    "    fig, axes = plt.subplots(1, num_samples, figsize=(20, 5))\n",
    "    \n",
    "    for idx, img_path in enumerate(images):\n",
    "        # Read image\n",
    "        img = cv2.imread(str(img_path))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Read label\n",
    "        label_path = label_dir / (img_path.stem + '.txt')\n",
    "        if label_path.exists():\n",
    "            with open(label_path, 'r') as f:\n",
    "                labels = f.read().strip().split('\\n')\n",
    "                class_ids = [int(l.split()[0]) for l in labels if l]\n",
    "                class_names = ['Fall' if c == 0 else 'No-Fall' for c in class_ids]\n",
    "                title = ', '.join(class_names)\n",
    "        else:\n",
    "            title = 'No label'\n",
    "        \n",
    "        axes[idx].imshow(img)\n",
    "        axes[idx].set_title(title, fontsize=12, fontweight='bold')\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Show samples\n",
    "show_sample_images(dataset_path, 'train', num_samples=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8d54aa",
   "metadata": {},
   "source": [
    "## Cell 7: Initialize Model & Training Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c110970c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained YOLOv8 nano model\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "print(\"‚úì Model loaded\")\n",
    "print(f\"Model: {model.model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4197d70",
   "metadata": {},
   "source": [
    "## Cell 8: Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3875c396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "results = model.train(\n",
    "    data='/kaggle/working/data.yaml',\n",
    "    \n",
    "    # Training params\n",
    "    epochs=50,              # s·ªë epoch (tƒÉng l√™n 100 n·∫øu mu·ªën)\n",
    "    imgsz=640,              # image size\n",
    "    batch=16,               # batch size (gi·∫£m xu·ªëng 8 n·∫øu GPU nh·ªè)\n",
    "    device=0,               # GPU device\n",
    "    \n",
    "    # Optimizer\n",
    "    optimizer='AdamW',\n",
    "    lr0=0.001,              # initial learning rate\n",
    "    lrf=0.01,               # final learning rate\n",
    "    momentum=0.937,\n",
    "    weight_decay=0.0005,\n",
    "    \n",
    "    # Augmentation (tƒÉng cho class imbalance)\n",
    "    hsv_h=0.015,            # hue\n",
    "    hsv_s=0.7,              # saturation\n",
    "    hsv_v=0.4,              # value\n",
    "    degrees=15,             # rotation\n",
    "    translate=0.1,          # translation\n",
    "    scale=0.5,              # scale\n",
    "    shear=0.0,\n",
    "    perspective=0.0,\n",
    "    flipud=0.5,             # flip up-down\n",
    "    fliplr=0.5,             # flip left-right\n",
    "    mosaic=1.0,             # mosaic augmentation\n",
    "    mixup=0.15,             # mixup augmentation\n",
    "    \n",
    "    # Training settings\n",
    "    patience=20,            # early stopping patience\n",
    "    save=True,\n",
    "    save_period=10,         # save checkpoint every 10 epochs\n",
    "    \n",
    "    # Output\n",
    "    project='/kaggle/working/runs/train',\n",
    "    name='fall_detection_v1',\n",
    "    exist_ok=True,\n",
    "    verbose=True,\n",
    "    \n",
    "    # Plots\n",
    "    plots=True\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"‚úÖ TRAINING COMPLETED!\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07a4f0b",
   "metadata": {},
   "source": [
    "## Cell 9: View Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a95cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "# Training curves\n",
    "results_img = '/kaggle/working/runs/train/fall_detection_v1/results.png'\n",
    "if Path(results_img).exists():\n",
    "    print(\"üìä Training Curves:\")\n",
    "    display(Image(filename=results_img))\n",
    "\n",
    "# Confusion matrix\n",
    "confusion_img = '/kaggle/working/runs/train/fall_detection_v1/confusion_matrix.png'\n",
    "if Path(confusion_img).exists():\n",
    "    print(\"\\nüìä Confusion Matrix:\")\n",
    "    display(Image(filename=confusion_img))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef54d068",
   "metadata": {},
   "source": [
    "## Cell 10: Validate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517655db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "best_model = YOLO('/kaggle/working/runs/train/fall_detection_v1/weights/best.pt')\n",
    "\n",
    "# Validate\n",
    "metrics = best_model.val(\n",
    "    data='/kaggle/working/data.yaml',\n",
    "    split='test',\n",
    "    batch=16,\n",
    "    imgsz=640,\n",
    "    device=0\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"üìä TEST SET METRICS\")\n",
    "print(\"=\"*50)\n",
    "print(f\"mAP50: {metrics.box.map50:.4f}\")\n",
    "print(f\"mAP50-95: {metrics.box.map:.4f}\")\n",
    "print(f\"Precision: {metrics.box.mp:.4f}\")\n",
    "print(f\"Recall: {metrics.box.mr:.4f}\")\n",
    "print(\"\\nPer-class metrics:\")\n",
    "for i, name in enumerate(['Fall', 'No-Fall']):\n",
    "    print(f\"  {name}:\")\n",
    "    print(f\"    Precision: {metrics.box.class_result(i)[0]:.4f}\")\n",
    "    print(f\"    Recall: {metrics.box.class_result(i)[1]:.4f}\")\n",
    "    print(f\"    mAP50: {metrics.box.class_result(i)[2]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf6969b",
   "metadata": {},
   "source": [
    "## Cell 11: Test on Sample Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d246b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test inference on sample images\n",
    "test_images = list((dataset_path / 'test/images').glob('*'))[:4]\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, img_path in enumerate(test_images):\n",
    "    # Run inference\n",
    "    results = best_model(str(img_path))\n",
    "    \n",
    "    # Plot\n",
    "    annotated = results[0].plot()\n",
    "    annotated = cv2.cvtColor(annotated, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    axes[idx].imshow(annotated)\n",
    "    axes[idx].set_title(f\"Image {idx+1}\", fontsize=12, fontweight='bold')\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fc57a2",
   "metadata": {},
   "source": [
    "## Cell 12: Export Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b285f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to ONNX (optional - for deployment)\n",
    "best_model.export(format='onnx', imgsz=640)\n",
    "\n",
    "print(\"‚úì Model exported to ONNX\")\n",
    "print(\"\\nFiles available for download:\")\n",
    "!ls -lh /kaggle/working/runs/train/fall_detection_v1/weights/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c13719",
   "metadata": {},
   "source": [
    "## Cell 13: Download Results (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584f27cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zip results for download\n",
    "import shutil\n",
    "\n",
    "output_dir = '/kaggle/working/runs/train/fall_detection_v1'\n",
    "shutil.make_archive('/kaggle/working/fall_detection_results', 'zip', output_dir)\n",
    "\n",
    "print(\"‚úì Results zipped\")\n",
    "print(\"Download: /kaggle/working/fall_detection_results.zip\")\n",
    "print(\"\\nImportant files:\")\n",
    "print(\"  - weights/best.pt (best model)\")\n",
    "print(\"  - weights/last.pt (last epoch)\")\n",
    "print(\"  - results.png (training curves)\")\n",
    "print(\"  - confusion_matrix.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed3b223",
   "metadata": {},
   "source": [
    "---\n",
    "## ‚úÖ TRAINING COMPLETE!\n",
    "\n",
    "**Next steps:**\n",
    "1. Download `best.pt` t·ª´ output\n",
    "2. Copy v·ªÅ local project: `d:\\Fall_Warning\\runs\\train\\fall_detection_v1\\weights\\best.pt`\n",
    "3. Update `yolodetect.py`: `self.model_path = 'runs/train/fall_detection_v1/weights/best.pt'`\n",
    "4. Test tr√™n demo video/camera"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
